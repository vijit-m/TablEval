{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Processing Code For Task 1 updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaihonikhil/Group-15/blob/master/Preprocessing_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuDuo-9dWovf"
      },
      "source": [
        "PREPROCESSING CODE FOR XML FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHcI0HCa_c8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d56ae5-afc7-43bf-81a1-aa5ecc60cfa2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV7YIFUaShvD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks0HDnMuwTl9"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/AutogAnnotationsTest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/TAPAS/FINALTEST')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKDuTSLX48eQ"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/My Drive/ManAnnotationsTest.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/TAPAS/FINALTEST')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPa81eACe1T4"
      },
      "source": [
        "from os import walk\n",
        "mypathTestIAA=\"/content/drive/MyDrive/TAPAS/FINALTEST/Autogenerated Annotations/Test/input\"\n",
        "mypathTestIMA=\"/content/drive/MyDrive/TAPAS/FINALTEST/Manual Annotations/Test/input\"\n",
        "mypathDevI=\"/content/drive/My Drive/Manual Annotations/Dev/input\"\n",
        "mypathDevO=\"/content/drive/My Drive/Manual Annotations/Train/output\"\n",
        "# mypathDevO=\"/content/drive/My Drive/Manual Annotations/Dev/output\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge0T8qwY-har"
      },
      "source": [
        "import os\n",
        "files_in_directory = os.listdir(mypathTestIMA)#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "examples = [file for file in files_in_directory if file.endswith(\".xml\")]\n",
        "for e in range(len(examples)):\n",
        "  examples[e]=examples[e][:-4]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UJ3-E7E9Sta"
      },
      "source": [
        "def clean_cell(content):\n",
        "  content=content.replace(\"n/a\",\"\")\n",
        "  bad_words = ['\\n','#',',','/','\"','$']\n",
        "  for word in bad_words : \n",
        "    content=content.replace(word,\" \")\n",
        "  content=content.replace(\"++\",\"increases\")\n",
        "  content=content.replace(\"--\",\"decreases\")\n",
        "  content=content.replace(\"+\",\"positive\")\n",
        "  content=content.replace(\"-\",\"negative\")\n",
        "\n",
        "\n",
        "  return content"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFc2WQA-8iPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18870d7f-107f-45db-8554-74498d01b964"
      },
      "source": [
        "len(examples)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlZL9dx29ZPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b5b03d-924e-42b2-f56d-4e8c1378b0e9"
      },
      "source": [
        "#EDIT THIS FOR TABLE MAKIING IN CSV TASK 1 \n",
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "import re\n",
        "import pandas as pd\n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "jj=0\n",
        "for example1 in examples:\n",
        "  content = []\n",
        "  with open(mypathTestIMA+\"/\"+example1+\".xml\", \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "      content = file.readlines()\n",
        "      content = \"\".join(content)\n",
        "      soup = bs(content, \"lxml\")\n",
        "  matrices=[]\n",
        "  tables = soup.find_all('table')\n",
        "  num_tables = len(tables)\n",
        "  p=0\n",
        "\n",
        "  for t in tables:\n",
        "    p=p+1  \n",
        "    row=t.find_all('row')\n",
        "    capt=t.find('caption')\n",
        "    legendtxt=t.find('legend')\n",
        "    if legendtxt != None:\n",
        "      # print(capt['text'])\n",
        "      capt['text']=capt['text']+\" \"+legendtxt['text']\n",
        "      # print(\"HI\")\n",
        "      # print(example1+\".\"+str(p)+\"DMO.html.csv\")\n",
        "      # print(capt['text'])\n",
        "    # print(capt)\n",
        "    statements=t.find_all('statement')\n",
        "    state=[]\n",
        "    index=[]\n",
        "    for s in statements:\n",
        "      a_list = s['text'].split()\n",
        "      s['text'] = \" \".join(a_list)\n",
        "      s['text']=str(s['text'])\n",
        "      s['text']=s['text'].replace(\"#\",\"\")\n",
        "      # print(s['text'])\n",
        "      if (s['type']=='entailed'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=1\n",
        "        index.append(s['type'])\n",
        "      elif (s['type']=='refuted'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=0\n",
        "        index.append(s['type'])\n",
        "      else:\n",
        "        state.append(s['text'])\n",
        "        s['type']=1\n",
        "        index.append(s['type'])\n",
        "        jj=jj+1\n",
        "    \n",
        "    stateme.append(state)\n",
        "    ind.append(index)\n",
        "    if (capt!=None):\n",
        "      a_list = capt['text'].split()\n",
        "      capt['text'] = \" \".join(a_list)\n",
        "      capt['text'] = re.sub(' +', ' ',capt['text']) \n",
        "      capt['text']=capt['text'].replace(\"#\",\"\")\n",
        "      # print(capt['text'])\n",
        "      captio.append(str(capt['text']))\n",
        "    else:\n",
        "      captio.append(\" \")\n",
        "    ####################################################################################################################################################\n",
        "    cells=[]\n",
        "    for s in row:\n",
        "      table_s = s.find_all('cell') \n",
        "      cells.append(len(table_s))\n",
        "    m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "    matrix=[]\n",
        "    lex=[]\n",
        "\n",
        "    array=[]\n",
        "    for l in range(len(row)):\n",
        "      array.append(\"\")\n",
        "    # array=\" \"\n",
        "    for r in row:\n",
        "      all_cells = r.find_all('cell')\n",
        "      j=0\n",
        "      # x=\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "      for j in all_cells:\n",
        "        cend=j['col-end']\n",
        "        cstart=j['col-start']\n",
        "        rend=int(j['row-end'])\n",
        "        rstart=int(j['row-start'])\n",
        "        j['text']=j['text'].replace('#', '')\n",
        "        if (cend==cstart):\n",
        "          array[rstart]=array[rstart]+j['text']+'#'\n",
        "        else:\n",
        "          kk=int(cend)-int(cstart)+1\n",
        "          for b in range(kk):\n",
        "            array[rstart]=array[rstart]+j['text']+'#'\n",
        "        if (rend!=rstart):\n",
        "          kk=int(rend)-int(rstart)\n",
        "          for b in range(kk):\n",
        "            array[rstart+b+1]=array[rstart+b+1]+j['text']+'#'\n",
        "        \n",
        "        a_list = array[rstart].split()\n",
        "        \n",
        "        array[rstart] = \" \".join(a_list)\n",
        "        \n",
        "    matrix=[]\n",
        "    for l in array:\n",
        "      l=l[:-1]\n",
        "      a_list = l.split(\"#\")\n",
        "      matrix.append(a_list)\n",
        "      # print(len(a_list))\n",
        "    h = matrix[0]\n",
        "    # print(h)\n",
        "    matrix =matrix[1:]\n",
        "    filename.append(example1+\".\"+str(p)+\"TESTMAN.html.csv\")\n",
        "\n",
        "    df = pd.DataFrame.from_records(matrix, columns=h)\n",
        "   \n",
        "    df.to_csv(\"/content/drive/My Drive/TAPAS/data/TESTcsv/\"+ example1  +\".\" + str(p) + \"TESTMAN\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n",
        "    #df.to_csv(\"/content/drive/My Drive/Updated_dataset/all_auto/\"+ example1  +\".\" + str(p) +  \"DAO\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n",
        "    #df.to_csv(\"/content/drive/My Drive/Updated_dataset/DAO/\"+ example1  +\".\" + str(p) + \"DAO\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n",
        "print(jj)\n",
        "print(\"cool\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "456\n",
            "cool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_PamDdHttRd"
      },
      "source": [
        "16839+ 456"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hppEc4rq8vL7"
      },
      "source": [
        "import json \n",
        " \n",
        "json_object = json.dumps(filename, indent = 2) \n",
        "  \n",
        "# Writing to sample.json \n",
        "with open(\"/content/drive/My Drive/TAPAS/REALTestOutputM_IDS.json\", \"w\") as outfile: \n",
        "    outfile.write(json_object) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9a0-olcCYG9",
        "outputId": "826d5472-8376-4644-cf03-c84ec7a79b9c"
      },
      "source": [
        "len(filename)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNwGTr4nWFHQ"
      },
      "source": [
        "#Creates File For Json Writing \n",
        "feeds={}\n",
        "with open(\"/content/drive/My Drive/TAPAS/REALTestOutputM.json\", \"w\",encoding='utf8') as write_file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "  for i in range(len(filename)):\n",
        "    a_list = captio[i].split()\n",
        "    new_string = \" \".join(a_list)\n",
        "    entry ={filename[i]:[stateme[i], ind[i],new_string]}\n",
        "    feeds.update(entry)\n",
        "    i=i+1\n",
        "  json.dump(feeds,write_file,indent=2,ensure_ascii=False, )\n",
        "    # json.dumps(feeds)\n",
        " \n",
        "#Json writing ends"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzK73t5F89SQ"
      },
      "source": [
        "**Autogenerated**\n",
        "\n",
        "> Train Output-1591 Tables 695 files\n",
        "\n",
        "> Dev Output-195 Tables 86 files\n",
        "\n",
        "**Manual**\n",
        "\n",
        "\n",
        "> Train Output- 783  Tables 340 files\n",
        "\n",
        "\n",
        "> Dev Output-100 Tables 42 files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJbS8-21pf7r"
      },
      "source": [
        "# CODE THIS FOR TASK 2\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "import re\n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "# for example1 in examples:\n",
        "content = []\n",
        "matt=[]\n",
        "\n",
        "for example1 in examples:\n",
        "  content = []\n",
        "with open('/content/20198.xml', \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "    content = file.readlines()\n",
        "    content = \"\".join(content)\n",
        "    soup = bs(content, \"lxml\")\n",
        "matrices=[]\n",
        "tables = soup.find_all('table')\n",
        "num_tables = len(tables)\n",
        "p=0\n",
        "\n",
        "for t in tables:\n",
        "  p=p+1  \n",
        "  row=t.find_all('row')\n",
        "  capt=t.find('caption')\n",
        "  statements=t.find_all('statement')\n",
        "  state=[]\n",
        "  index=[]\n",
        "  cells=[]\n",
        "  for s in row:\n",
        "    table_s = s.find_all('cell')\n",
        "    cells.append(len(table_s))\n",
        "  m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "  mat = np.zeros((len(statements),len(row),m))\n",
        "  matrix=[]\n",
        "  lex=[]\n",
        "  for r in row:\n",
        "    table_rows = r.find_all('cell')\n",
        "    for c in table_rows:\n",
        "      ce=c.find_all('evidence')\n",
        "      cs=int(c['col-start'])\n",
        "      cee=int(c['col-end'])\n",
        "      rs=int(c['row-start'])\n",
        "      re=int(c['row-end'])\n",
        "      for j in ce:\n",
        "        f=int(j['statement_id'])\n",
        "        k=j.find('type')\n",
        "        if (j['type']=='relevant'):\n",
        "          for c in range(rs,re+1):\n",
        "            for k in range(cs,cee+1):\n",
        "              mat[f][c][k]=1\n",
        "  matt.append(mat)      \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNoKIZEvHkm2"
      },
      "source": [
        "import os\n",
        "files_in_directory = os.listdir(\"/content/drive/My Drive/Group-15-Git/Table-Fact-CheckingModified/all_programs\")#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "examples = [file for file in files_in_directory]\n",
        "examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Obp4IN7kxy9b",
        "outputId": "8b2b2351-dc1d-4c80-f626-3047fec4fb68"
      },
      "source": [
        "#old interpolated code \n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "import pandas as pd\n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "# for example1 in examplescontent = []\n",
        "  # with open(B+\"/\"+example1+\".xml\", \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "with open(\"/content/20189.xml\", \"r\") as file:\n",
        "    content = file.readlines()\n",
        "    content = \"\".join(content)\n",
        "    soup = bs(content, \"lxml\")\n",
        "matrices=[]\n",
        "tables = soup.find_all('table')\n",
        "num_tables = len(tables)\n",
        "p=0\n",
        "\n",
        "for t in tables:\n",
        "  p=p+1  \n",
        "  row=t.find_all('row')\n",
        "  #print(row)\n",
        "  capt=t.find('caption')\n",
        "  statements=t.find_all('statement')\n",
        "  state=[]\n",
        "  index=[]\n",
        "  for s in statements:\n",
        "    a_list = s['text'].split()\n",
        "    s['text'] = \" \".join(a_list)\n",
        "    s['text']=str(s['text'])\n",
        "    # print(s['text'])\n",
        "    if (s['type']=='entailed'):\n",
        "      state.append(s['text'])\n",
        "      s['type']='1'\n",
        "      index.append(s['type'])\n",
        "    elif (s['type']=='refuted'):\n",
        "      state.append(s['text'])\n",
        "      s['type']='0'\n",
        "      index.append(s['type'])\n",
        "  \n",
        "  stateme.append(state)\n",
        "  ind.append(index)\n",
        "  if (capt!=None):\n",
        "    a_list = capt['text'].split()\n",
        "    capt['text'] = \" \".join(a_list)\n",
        "    captio.append(capt['text'])\n",
        "  else:\n",
        "    captio.append(\" \")\n",
        "  cells=[]\n",
        "  for s in row:\n",
        "    table_s = s.find_all('cell')\n",
        "    cells.append(len(table_s))\n",
        "  m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "  matrix=[]\n",
        "  for r in row:\n",
        "    table_rows = r.find_all('cell')\n",
        "    #print(table_rows)\n",
        "    j=0\n",
        "    x=0\n",
        "    s=\"\"\n",
        "    rowstring=\"\"\n",
        "    for j in range(m):\n",
        "      l=table_rows[x]\n",
        "      if(j==int(l['col'])):\n",
        "        cell_content = clean_cell(l['text'])\n",
        "        #print(cell_content)\n",
        "        rowstring = rowstring + cell_content + '#'\n",
        "        # print(rowstring)\n",
        "        s=l['text']\n",
        "        if(x<len(table_rows)-1):\n",
        "          x=x+1\n",
        "      else :\n",
        "        # print(\"#######################\")\n",
        "        #print(s)\n",
        "        rowstring=rowstring+s+'#'\n",
        "      j=j+1\n",
        "    rowstring=rowstring[:-1]\n",
        "    a_list = rowstring.split()\n",
        "    new_string = \" \".join(a_list)\n",
        "    #print(rowstring)\n",
        "    a_list = new_string.split(\"#\")\n",
        "    #print(a_list)\n",
        "    matrix.append(a_list)\n",
        "  \n",
        "  h = matrix[0]\n",
        "  # print(matrix)\n",
        "  #print(len(h))\n",
        "  matrix = matrix[1:]\n",
        "  #for columns in matrix: \n",
        "    #print(len(columns))\n",
        "    #print(columns)\n",
        "  #print(len(matrix[0]))\n",
        "  print(matrix)\n",
        "  df = pd.DataFrame.from_records(matrix, columns=h)\n",
        "  # print(df)\n",
        "  # df.to_csv(\"/content/drive/My Drive/TAPAS/all_csv/\"+ example1  +\".\" + str(p) + \"DMO\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n",
        "  #df.to_csv(\"/content/drive/My Drive/Updated_dataset/all_auto/\"+ example1  +\".\" + str(p) +  \"DAO\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n",
        "  #df.to_csv(\"/content/drive/My Drive/Updated_dataset/DAO/\"+ example1  +\".\" + str(p) + \"DAO\" + '.html.csv',sep='#',mode = 'w', index=False, index_label=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['', ' Min ', ' Max ', ' Min ', ' Max ', ' Min ', ' Max'], ['Desktop ', ' 24 × 31 ', ' 37.5 × 37.5 ', ' 6 ', ' 165 ', ' 80 ', ' 105'], ['Mobile ', ' 12 × 12 ', ' 42 × 24 ', ' 2.2 ', ' 57 ', ' 80 ', ' 105'], ['Server ', ' 34 × 28 ', ' 88 × 56.5 ', ' 11.7 ', ' 320 ', ' 40 ', ' 100'], ['Embedded ', ' 25 × 27 ', ' 45 × 42.5 ', ' 3 ', ' 105 ', ' 40 ', ' 110']]\n",
            "[['Ponegative210 ', ' Metal ', ' 1210 ', ' 138 d ', ' 254 ', ' 9.3 ', ' 31.7 ', ' Alpha'], ['Pmnegative147 ', ' Pm 2 O 3 ', ' 1.5 ', ' 2.6 y ', ' 2300 ', ' 5.55 ', ' 0.37 ', ' Beta'], ['Srnegative90 ', ' SrO 2 ', ' 0.93 ', ' 28 y ', ' 2430 ', ' 2.65 ', ' 6.5 ', ' Beta'], ['Punegative238 ', ' PuO 2 ', ' 5.0 ', ' 89.6 y ', ' 2250 ', ' 11.46 ', ' 34.5 ', ' Alpha'], ['Cenegative144 ', ' CeO 2 ', ' 13.8 ', ' 285 d ', ' 2680 ', ' 7 ', ' 7.9 ', ' Beta']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97IZDQA7ymcd"
      },
      "source": [
        "\n",
        "#OLD INTRAPOLATION CODE \n",
        "\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import numpy as np\n",
        "import json\n",
        "import csv \n",
        "import re\n",
        "filename=[]\n",
        "stateme=[]\n",
        "ind=[]\n",
        "captio=[]\n",
        "for example1 in examples:\n",
        "  content = []\n",
        "  with open(mypathDevO+\"/\"+example1+\".xml\", \"r\") as file:#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "      content = file.readlines()\n",
        "      content = \"\".join(content)\n",
        "      soup = bs(content, \"lxml\")\n",
        "  matrices=[]\n",
        "  tables = soup.find_all('table')\n",
        "  num_tables = len(tables)\n",
        "  p=0\n",
        "  \n",
        "  for t in tables:\n",
        "    p=p+1  \n",
        "    row=t.find_all('row')\n",
        "    capt=t.find('caption')\n",
        "    legendtxt=t.find('legend')\n",
        "    if legendtxt != None:\n",
        "      # print(capt['text'])\n",
        "      capt['text']=capt['text']+legendtxt['text']\n",
        "      # print(\"HI\")\n",
        "      # print(capt['text'])\n",
        "    # print(capt)\n",
        "    statements=t.find_all('statement')\n",
        "    state=[]\n",
        "    index=[]\n",
        "    for s in statements:\n",
        "      a_list = s['text'].split()\n",
        "      s['text'] = \" \".join(a_list)\n",
        "      s['text']=str(s['text'])\n",
        "      s['text']=s['text'].replace(\"#\",\"\")\n",
        "      # print(s['text'])\n",
        "      if (s['type']=='entailed'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=1\n",
        "        index.append(s['type'])\n",
        "      elif (s['type']=='refuted'):\n",
        "        state.append(s['text'])\n",
        "        s['type']=0\n",
        "        index.append(s['type'])\n",
        "    \n",
        "    stateme.append(state)\n",
        "    ind.append(index)\n",
        "    if (capt!=None):\n",
        "      a_list = capt['text'].split()\n",
        "      capt['text'] = \" \".join(a_list)\n",
        "      capt['text'] = re.sub(' +', ' ',capt['text']) \n",
        "      capt['text']=capt['text'].replace(\"#\",\"\")\n",
        "      # print(capt['text'])\n",
        "      captio.append(str(capt['text']))\n",
        "    else:\n",
        "      captio.append(\" \")\n",
        "    cells=[]\n",
        "    for s in row:\n",
        "      table_s = s.find_all('cell')\n",
        "      cells.append(len(table_s))\n",
        "    m=max(cells)# For intrapolating hence finding maximum number of columns\n",
        "    matrix=[]\n",
        "    lex=[]\n",
        "    for r in row:\n",
        "      table_rows = r.find_all('cell')\n",
        "      j=0\n",
        "      x=0\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "      for j in range(m):\n",
        "        l=table_rows[x]\n",
        "        if(j==int(l['col'])):\n",
        "          l['text']=l['text'].replace(\"#\",\"\")\n",
        "          rowstring=rowstring+l['text']+'#'\n",
        "          s=l['text']\n",
        "          if(x<len(table_rows)-1):\n",
        "            x=x+1\n",
        "        else :\n",
        "          rowstring=rowstring+s+'#'\n",
        "        j=j+1\n",
        "      rowstring=rowstring[:-1]\n",
        "      a_list = rowstring.split()\n",
        "      new_string = \" \".join(a_list)\n",
        "      lex.append(new_string)\n",
        "      matrix.append(lex)\n",
        "      lex=[]\n",
        "      s=\"\"\n",
        "      rowstring=\"\"\n",
        "    filename.append(example1+\".\"+str(p)+\"DAO.html.csv\")\n",
        "    dir=\"/content/drive/My Drive/DeleteOutput/\"#EDIT THIS FOR ANOTHER DIRECTORY\n",
        "    file = open(dir+example1+\".\"+str(p)+'DAO.html.csv', 'w', newline ='') \n",
        "    with file:     \n",
        "      write = csv.writer(file) \n",
        "      write.writerows(matrix) \n",
        "    matrices.append(matrix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMIIGFxNp8j1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}